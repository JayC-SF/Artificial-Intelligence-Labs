{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d858d0c9",
   "metadata": {},
   "source": [
    "## Assignment 1: Bayes Classifier Question 3\n",
    "\n",
    "In this question, you will implement the **CategoricaL Naive Bayes classifier** from scratch.\n",
    "This means you must not rely on any pre-implemented models (such as those provided\n",
    "by the scikit-learn library), in order to gain a deeper understanding of how the\n",
    "algorithm works internally. \n",
    "\n",
    "Through this process, you will explore how probabilities are estimated from data, \n",
    "how predictions are made using conditional independence assumptions, and how numerical \n",
    "issues can arise in probabilistic models.\n",
    "\n",
    "Unless explicitly stated otherwise, you should not be making any changes to the library\n",
    "imports section of this notebook. In particular, you are not allowed to import any additional Python libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54ae76d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c3441b",
   "metadata": {},
   "source": [
    "**Data Loader and Processing Section**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1287df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================================================\n",
    "# TODO: Using Numpy, extract CSV data. Note: Please omit header row.\n",
    "\n",
    "my_data = np.loadtxt('transactions.csv', delimiter=',', skiprows=1, dtype=str)\n",
    "\n",
    "# =====================================================================================\n",
    "# TODO: Split dataset into a feature matrix and label vector.\n",
    "\n",
    "tmp_feature_mat = my_data[:, :-1]\n",
    "tmp_label_vector = my_data[:, -1:].ravel() # make it into 1D array and flatten with ravel()\n",
    "\n",
    "# =====================================================================================\n",
    "# TODO: Convert categorical strings to integers for each feature. \n",
    "# (Example Low, Medium, High -> 0, 1, 2)\n",
    "\n",
    "feature_mat = np.zeros(tmp_feature_mat.shape, dtype=int)\n",
    "feature_mat[\"Low\" == tmp_feature_mat] = 0\n",
    "feature_mat[\"Medium\" == tmp_feature_mat] = 1\n",
    "feature_mat[\"High\" == tmp_feature_mat] = 2\n",
    "feature_mat[\"Old\" == tmp_feature_mat] = 0\n",
    "feature_mat[\"Recent\" == tmp_feature_mat] = 1\n",
    "feature_mat[\"New\" == tmp_feature_mat] = 2\n",
    "feature_mat[\"Morning\" == tmp_feature_mat] = 0\n",
    "feature_mat[\"Afternoon\" == tmp_feature_mat] = 1\n",
    "feature_mat[\"Evening\" == tmp_feature_mat] = 2\n",
    "feature_mat[\"Night\" == tmp_feature_mat] = 3\n",
    "\n",
    "label_vector = np.full(tmp_label_vector.shape, fill_value=-10, dtype=int)\n",
    "label_vector[tmp_label_vector == \"no\"] = 0\n",
    "label_vector[tmp_label_vector == \"yes\"] = 1\n",
    "\n",
    "# =====================================================================================\n",
    "# TODO: Use train_test_split function from the Scikit-learn library to split data \n",
    "# into training (75%) and test (25%) sets.\n",
    "# *IMPORTANT: Add the arguemnt random_state=42*\n",
    "# Hint: Use stratify=y to maintain class distribution\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    feature_mat, \n",
    "    label_vector, \n",
    "    test_size=0.25, \n",
    "    train_size=0.75,\n",
    "    stratify=label_vector\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155b1e22",
   "metadata": {},
   "source": [
    "**Categorical Naive Bayes Classifier**\n",
    "\n",
    "Write your code where you see the key word pass. (You should remove pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa42ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalNaiveBayes:\n",
    "    def __init__(self, alpha=1.0):\n",
    "        self.alpha = alpha\n",
    "        self.classes = None             # Unique class labels\n",
    "        self.priors = None              # Class prior probabilities\n",
    "        self.feature_cond_probs = None  # List to store feature probabilities per class\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        TODO:\n",
    "        - Identify unique classes\n",
    "        - Compute class priors P(y)\n",
    "        - Count occurrences of each feature value per class\n",
    "        - Apply Laplace smoothing (alpha)\n",
    "        \"\"\"\n",
    "        \n",
    "        # get the classes and their counts\n",
    "        classes, counts = np.unique(y, return_counts=True)\n",
    "        # divide the counts of each classes by the total amount of elements.\n",
    "        priors = counts/len(y)\n",
    "        \n",
    "\n",
    "    def compute_log_likelihood(self, X):\n",
    "        \"\"\"\n",
    "        TODO:\n",
    "        - For each sample and each class:\n",
    "        - Sum log-probabilities of all features given the class\n",
    "        - Add log prior of the class\n",
    "        - Return a log-likelihood array of shape (n_samples, n_classes)\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        TODO:\n",
    "        - Use compute_log_likelihood\n",
    "        - Return the class with highest log-posterior for each sample\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cd2938",
   "metadata": {},
   "source": [
    "**Classifier training and testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5644ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================================================\n",
    "# TODO: Create an instance of your CategoricalNaiveBayes classifier and train it\n",
    "\n",
    "cnb = CategoricalNaiveBayes()\n",
    "\n",
    "# =====================================================================================\n",
    "# TODO: Make predictions on the test data\n",
    "\n",
    "cnb.fit(X_train, y_train)\n",
    "\n",
    "# =====================================================================================\n",
    "# TODO: Using Scikit-learn's accuracy_score and classification_report functions, print\n",
    "# both the accuracry score and the classification_report metrics for your classifier\n",
    "\n",
    "# *Add code here*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "COMP432-Labs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
